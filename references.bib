@article{wang2021self-consistency,
abstract = {Chain-of-thought prompting combined with pre-trained large language models
has achieved encouraging results on complex reasoning tasks. In this paper, we
propose a new decoding strategy, self-consistency, to replace the naive greedy
decoding used in chain-of-thought prompting. It first samples a diverse set of
reasoning paths instead of only taking the greedy one, and then selects the
most consistent answer by marginalizing out the sampled reasoning paths.
Self-consistency leverages the intuition that a complex reasoning problem
typically admits multiple different ways of thinking leading to its unique
correct answer. Our extensive empirical evaluation shows that self-consistency
boosts the performance of chain-of-thought prompting with a striking margin on
a range of popular arithmetic and commonsense reasoning benchmarks, including
GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and
ARC-challenge (+3.9%).},
year = {2022},
title = {Self-consistency improves Chain of Thought reasoning in Language Models},
copyright = {http://creativecommons.org/licenses/by/4.0},
language = {eng},
author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
url = {https://doi.org/10.48550/arXiv.2203.11171},
doi = {10.48550/arXiv.2203.11171},
institution = {Google Research},
journal  = {arXiv}
}

@article{ye2022unreliability,
abstract = {Does prompting a large language model (LLM) like GPT-3 with explanations
improve in-context learning? We study this question on two NLP tasks that
involve reasoning over text, namely question answering and natural language
inference. We test the performance of four LLMs on three textual reasoning
datasets using prompts that include explanations in multiple different styles.
For these tasks, we find that including explanations in the prompts for OPT,
GPT-3 (davinci), and InstructGPT (text-davinci-001) only yields small to
moderate accuracy improvements over standard few-show learning. However,
text-davinci-002 is able to benefit more substantially.
We further show that explanations generated by the LLMs may not entail the
models' predictions nor be factually grounded in the input, even on simple
tasks with extractive explanations. However, these flawed explanations can
still be useful as a way to verify LLMs' predictions post-hoc. Through analysis
in our three settings, we show that explanations judged by humans to be
good--logically consistent with the input and the prediction--more likely
cooccur with accurate predictions. Following these observations, we train
calibrators using automatically extracted scores that assess the reliability of
explanations, allowing us to improve performance post-hoc across all of our
datasets.},
year = {2022},
title = {The unreliability of explanations in Few-shot Prompting for textual reasoning},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Ye, Xi and Durrett, Greg},
keywords = {Computer Science - Computation and Language},
url = {https://doi.org/10.48550/arXiv.2205.03401},
doi = {10.48550/arXiv.2205.03401},
institution = {Department of Computer Science, The University of Texas at Austin},
journal  = {arXiv}
}

@article{yu2022legal-prompting,
abstract = {Large language models that are capable of zero or few-shot prompting approaches have given rise to the new research area of prompt engineering. Recent advances showed that for example Chain-of-Thought (CoT) prompts can improve arithmetic or common sense tasks significantly. We explore how such approaches fare with legal reasoning tasks and take the COLIEE entailment task based on the Japanese Bar exam for testing zero-shot/few-shot and fine-tuning approaches. Our findings show that while CoT prompting and fine-tuning with explanations approaches show improvements, the best results are produced by prompts that are derived from specific legal reasoning techniques such as IRAC (Issue, Rule, Application, Conclusion). Based on our experiments we improve the 2021 best result from 0.7037 accuracy to 0.8148 accuracy and beat the 2022 best system of 0.6789 accuracy with an accuracy of 0.7431.},
year = {2022},
title = {Legal prompting: Teaching a Language Model to think like a lawyer},
copyright = {http://creativecommons.org/licenses/by-nc-nd/4.0},
language = {eng},
author = {Yu, Fangyi and Quartey, Lee and Schilder, Frank},
url = {https://doi.org/10.48550/arXiv.2212.01326},
doi = {10.48550/arXiv.2212.01326},
institution = {Thomson Reuters Labs},
journal = {arXiv}
}

@inproceedings{hardcastle2008evaluate,
year = {2008},
title = {Can we evaluate the quality of generated text?},
language = {eng},
author = {Hardcastle, David and Scott, Donia},
booktitle = {Proceedings of the 6th Language Resources and Evaluation Conference},
location = {Marrakech, Morocco},
editor = {Calzolari, Nicoletta and Choukri, Khalid and Maegaard, Bente and Mariani, Joseph and  Odijk, Jan and Piperidis, Stelios and Tapias, Daniel},
pages = {3151-3158},
url = {},
doi = {},
institution = {}
}

@article{celikyilmaz2020evaluation,
abstract = {The paper surveys evaluation methods of natural language generation (NLG)
systems that have been developed in the last few years. We group NLG evaluation
methods into three categories: (1) human-centric evaluation metrics, (2)
automatic metrics that require no training, and (3) machine-learned metrics.
For each category, we discuss the progress that has been made and the
challenges still being faced, with a focus on the evaluation of recently
proposed NLG tasks and neural NLG models. We then present two examples for
task-specific NLG evaluations for automatic text summarization and long text
generation, and conclude the paper by proposing future research directions.},
year = {2020},
title = {Evaluation of text generation: A survey},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Celikyilmaz, Asli and Clark, Elizabeth and Gao, Jianfeng},
url = {https://doi.org/10.48550/arXiv.2006.14799},
doi = {10.48550/arXiv.2006.14799},
journal  = {arXiv}
}

@article{zhang2019bertscore,
abstract = {We propose BERTScore, an automatic evaluation metric for text generation.
Analogously to common metrics, BERTScore computes a similarity score for each
token in the candidate sentence with each token in the reference sentence.
However, instead of exact matches, we compute token similarity using contextual
embeddings. We evaluate using the outputs of 363 machine translation and image
captioning systems. BERTScore correlates better with human judgments and
provides stronger model selection performance than existing metrics. Finally,
we use an adversarial paraphrase detection task to show that BERTScore is more
robust to challenging examples when compared to existing metrics.},
year = {2019},
title = {BERTScore: Evaluating text generation with BERT},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Zhang, Tianyi and Kishore, Varsha and Wu, Felix and Weinberger, Kilian Q and Artzi, Yoav},
keywords = {Computer Science - Computation and Language},
url = {https://doi.org/10.48550/arXiv.1904.09675},
doi = {10.48550/arXiv.1904.09675},
journal  = {arXiv}
}

@article{lin2021truthfulqa,
abstract = {We propose a benchmark to measure whether a language model is truthful in
generating answers to questions. The benchmark comprises 817 questions that
span 38 categories, including health, law, finance and politics. We crafted
questions that some humans would answer falsely due to a false belief or
misconception. To perform well, models must avoid generating false answers
learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a
T5-based model. The best model was truthful on 58% of questions, while human
performance was 94%. Models generated many false answers that mimic popular
misconceptions and have the potential to deceive humans. The largest models
were generally the least truthful. This contrasts with other NLP tasks, where
performance improves with model size. However, this result is expected if false
answers are learned from the training distribution. We suggest that scaling up
models alone is less promising for improving truthfulness than fine-tuning
using training objectives other than imitation of text from the web.},
year = {2021},
title = {TruthfulQA: Measuring how models mimic human falsehoods},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Lin, Stephanie and Hilton, Jacob and Evans, Owain},
url = {https://doi.org/10.48550/arXiv.2109.07958},
doi = {10.48550/arXiv.2109.07958},
journal  = {arXiv}
}

@article{warzel2023talking-to-ai,
year = {2023},
title = {Talking to AI might be the most important job skill of this century},
author = {Warzel, Charlie},
date = {20230208},
url = {https://www.theatlantic.com/technology/archive/2023/02/openai-text-models-google-search-engine-bard-chatbot-chatgpt-prompt-writing/672991/}
}

@article{brown2020manguage-modles,
abstract = {Recent work has demonstrated substantial gains on many NLP tasks and
benchmarks by pre-training on a large corpus of text followed by fine-tuning on
a specific task. While typically task-agnostic in architecture, this method
still requires task-specific fine-tuning datasets of thousands or tens of
thousands of examples. By contrast, humans can generally perform a new language
task from only a few examples or from simple instructions - something which
current NLP systems still largely struggle to do. Here we show that scaling up
language models greatly improves task-agnostic, few-shot performance, sometimes
even reaching competitiveness with prior state-of-the-art fine-tuning
approaches. Specifically, we train GPT-3, an autoregressive language model with
175 billion parameters, 10x more than any previous non-sparse language model,
and test its performance in the few-shot setting. For all tasks, GPT-3 is
applied without any gradient updates or fine-tuning, with tasks and few-shot
demonstrations specified purely via text interaction with the model. GPT-3
achieves strong performance on many NLP datasets, including translation,
question-answering, and cloze tasks, as well as several tasks that require
on-the-fly reasoning or domain adaptation, such as unscrambling words, using a
novel word in a sentence, or performing 3-digit arithmetic. At the same time,
we also identify some datasets where GPT-3's few-shot learning still struggles,
as well as some datasets where GPT-3 faces methodological issues related to
training on large web corpora. Finally, we find that GPT-3 can generate samples
of news articles which human evaluators have difficulty distinguishing from
articles written by humans. We discuss broader societal impacts of this finding
and of GPT-3 in general.},
year = {2020},
title = {Language models are few-shot learners},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
keywords = {Computer Science - Computation and Language},
doi = {10.48550/arXiv.2209.14500},
url = {https://doi.org/10.48550/arXiv.2209.14500},
journal  = {arXiv}
}

@article{ouyang2022instructgpt,
abstract = {Making language models bigger does not inherently make them better at
following a user's intent. For example, large language models can generate
outputs that are untruthful, toxic, or simply not helpful to the user. In other
words, these models are not aligned with their users. In this paper, we show an
avenue for aligning language models with user intent on a wide range of tasks
by fine-tuning with human feedback. Starting with a set of labeler-written
prompts and prompts submitted through the OpenAI API, we collect a dataset of
labeler demonstrations of the desired model behavior, which we use to fine-tune
GPT-3 using supervised learning. We then collect a dataset of rankings of model
outputs, which we use to further fine-tune this supervised model using
reinforcement learning from human feedback. We call the resulting models
InstructGPT. In human evaluations on our prompt distribution, outputs from the
1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3,
despite having 100x fewer parameters. Moreover, InstructGPT models show
improvements in truthfulness and reductions in toxic output generation while
having minimal performance regressions on public NLP datasets. Even though
InstructGPT still makes simple mistakes, our results show that fine-tuning with
human feedback is a promising direction for aligning language models with human
intent.},
year = {2022},
title = {Training language models to follow instructions with human feedback},
copyright = {http://arxiv.org/licenses/nonexclusive-distrib/1.0},
language = {eng},
author = {Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul and Leike, Jan and Lowe, Ryan},
doi = {10.48550/arXiv.2203.02155},
url = {https://doi.org/10.48550/arXiv.2203.02155},
journal  = {arXiv}
}

@article{glaese2022sparrow,
abstract = {We present Sparrow, an information-seeking dialogue agent trained to be more
helpful, correct, and harmless compared to prompted language model baselines.
We use reinforcement learning from human feedback to train our models with two
new additions to help human raters judge agent behaviour. First, to make our
agent more helpful and harmless, we break down the requirements for good
dialogue into natural language rules the agent should follow, and ask raters
about each rule separately. We demonstrate that this breakdown enables us to
collect more targeted human judgements of agent behaviour and allows for more
efficient rule-conditional reward models. Second, our agent provides evidence
from sources supporting factual claims when collecting preference judgements
over model statements. For factual questions, evidence provided by Sparrow
supports the sampled response 78% of the time. Sparrow is preferred more often
than baselines while being more resilient to adversarial probing by humans,
violating our rules only 8% of the time when probed. Finally, we conduct
extensive analyses showing that though our model learns to follow our rules it
can exhibit distributional biases.},
year = {2022},
title = {Improving alignment of dialogue agents via targeted human judgements},
copyright = {http://creativecommons.org/licenses/by/4.0},
language = {eng},
author = {Glaese, Amelia and McAleese, Nat and Trębacz, Maja and Aslanides, John and Firoiu, Vlad and Ewalds, Timo and Rauh, Maribeth and Weidinger, Laura and Chadwick, Martin and Thacker, Phoebe and Campbell-Gillingham, Lucy and Uesato, Jonathan and Huang, Po-Sen and Comanescu, Ramona and Yang, Fan and See, Abigail and Dathathri, Sumanth and Greig, Rory and Chen, Charlie and Fritz, Doug and Elias, Jaume Sanchez and Green, Richard and Mokrá, Soňa and Fernando, Nicholas and Wu, Boxi and Foley, Rachel and Young, Susannah and Gabriel, Iason and Isaac, William and Mellor, John and Hassabis, Demis and Kavukcuoglu, Koray and Hendricks, Lisa Anne and Irving, Geoffrey},
doi = {10.48550/arXiv.2209.14375},
url = {https://doi.org/10.48550/arXiv.2209.14375},
journal  = {arXiv}
}

@inproceedings{fujita2021predicate,
year = {2021},
title = {Predicate’s Argument Resolver and Entity Abstraction for Legal Question Answering: {KIS} teams at {COLIEE} 2021 shared task},
language = {eng},
author = {Fujita, Masaki and Kiyota, Naoki and Kano, Yoshinobu},
booktitle = {Proceedings of the Eigth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2021)},
location = {Sao Paulo, Brazil},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {15-24},
url = {},
doi = {},
institution = {}
}

@inproceedings{devlin2019bert,
title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
author = "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina",
booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
month = jun,
year = "2019",
address = "Minneapolis, MA",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/N19-1423",
doi = "10.18653/v1/N19-1423",
pages = "4171-4186",
abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{chalkidis2020legal-bert,
title = "{LEGAL}-{BERT}: The Muppets straight out of Law School",
author = "Chalkidis, Ilias and Fergadiotis, Manos and Malakasiotis, Prodromos and Aletras, Nikolaos and Androutsopoulos, Ion",
booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
month = nov,
year = "2020",
address = "Online",
publisher = "Association for Computational Linguistics",
url = "https://aclanthology.org/2020.findings-emnlp.261",
doi = "10.18653/v1/2020.findings-emnlp.261",
pages = "2898-2904",
abstract = "BERT has achieved impressive performance in several NLP tasks. However, there has been limited investigation on its adaptation guidelines in specialised domains. Here we focus on the legal domain, where we explore several approaches for applying BERT models to downstream legal tasks, evaluating on multiple datasets. Our findings indicate that the previous guidelines for pre-training and fine-tuning, often blindly followed, do not always generalize well in the legal domain. Thus we propose a systematic investigation of the available strategies when applying BERT in specialised domains. These are: (a) use the original BERT out of the box, (b) adapt BERT by additional pre-training on domain-specific corpora, and (c) pre-train BERT from scratch on domain-specific corpora. We also propose a broader hyper-parameter search space when fine-tuning for downstream tasks and we release LEGAL-BERT, a family of BERT models intended to assist legal NLP research, computational law, and legal technology applications.",
}

@article{rabelo2022coliee2021-overview,
abstract = {We summarize the 8th Competition on Legal Information Extraction and Entailment. In this edition, the competition included five tasks on case law and statute law. The case law component includes an information retrieval Task (Task 1), and the confirmation of an entailment relation between an existing case and an unseen case (Task 2). The statute law component includes an information retrieval Task (Task 3), an entailment/question answering task based on retrieved civil code statutes (Task 4) and an entailment/question answering task without retrieved civil code statutes (Task 5). Participation was open to any group based on any approach. Eight different teams participated in the case law competition tasks, most of them in more than one task. We received results from six teams for Task 1 (16 runs) and 6 teams for Task 2 (17 runs). On the statute law task, there were eight different teams participating, most in more than one task. Six teams submitted a total of 18 runs for Task 3, 6 teams submitted a total of 18 runs for Task 4, and 4 teams submitted a total of 12 runs for Task 5. Here we summarize the approaches, our official evaluation, and analysis on our data and submission results.},
year = {2022},
title = {Overview and Discussion of the Competition on Legal Information Extraction/Entailment {(COLIEE)} 2021},
language = {eng},
author = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken and Yoshioka, Masaharu},
journal = {The Review of Socionetwork Strategies},
volume = {16},
number = {},
pages = {111-133},
doi = {10.1007/s12626-022-00105-z},
url = {https://doi.org/10.1007/s12626-022-00105-z}
}

@inproceedings{schilder2022pentapus,
year = {2021},
title = {A Pentapus Grapples with Legal Reasoning},
language = {eng},
author = {Schilder, Frank and Chinnappa, Dhivya and Madan, Kanika and Harmouche, Jinane and Vold, Andrew and Bretz, Hiroko and Hudzina, John},
booktitle = {Proceedings of the Eigth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2021)},
location = {Sao Paulo, Brazil},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {60-68},
url = {},
doi = {},
institution = {}
}

@article{kojima2023zero-shot,
title={Large Language Models are Zero-Shot Reasoners}, 
author={Kojima, Takeshi and Shane Gu, Shixiang and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
year={2023},
eprint={2205.11916},
archivePrefix={arXiv},
primaryClass={cs.CL},
url = {https://arxiv.org/abs/2205.11916v4},
doi = {10.48550/arXiv.2205.11916},
journal  = {arXiv}
}

@article{zelikman2022bootstrapping-reasoning,
title={STaR: Bootstrapping Reasoning with Reasoning}, 
author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D.},
year={2022},
eprint={2203.14465},
archivePrefix={arXiv},
primaryClass={cs.LG},
url = {https://arxiv.org/abs/2203.14465v2},
doi = {10.48550/arXiv.2203.14465},
journal  = {arXiv}
}

@inproceedings{kim2023coliee2022-summary,
title={{COLIEE} 2022 Summary: Methods for Legal Document Retrieval and Entailment}, 
author={Kim, Mi-Young and Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Satoh, Ken and Yoshioka, Masaharu},
year={2023},
booktitle = {New Frontiers in Artificial Intelligence. {JSAI-isAI} 2022},
series = {Lecture Notes in Computer Science},
number = {13859},
publisher = {Springer},
location = {Cham},
editor = {Takama, Yasufumi and Yada, Katsutoshi and Satoh, Ken and Arai, Sachiyo},
pages = {51-67},
url = {https://doi.org/10.1007/978-3-031-29168-5_4},
doi = {10.1007/978-3-031-29168-5_4},
institution = {}
}

@inproceedings{liu2023sailer,
year = {2023},
title = {{THUIR@COLIEE 2023}: Incorporating Structural Knowledge into Pre-trained Language Models for Legal Case Retrieval},
language = {eng},
author = {Liu, Yiqun and Li, Haitao and Su, Weihang and Wang, Changyue and Wu, Yueyue and Ai, Qingyao},
booktitle = {Proceedings of the Tenth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2023) in association with the 19th International Conference on Artiﬁcial Intelligence and Law},
location = {Braga, Portugal},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {1-6},
url = {},
doi = {},
institution = {}
}

@inproceedings{nguyen2023data-augmentation,
year = {2023},
title = {{JNLP@COLIEE 2023}: Data Augmentation and Large Language Model for Legal Case Retrieval and Entailment},
language = {eng},
author = {Nguyen, Minh Le and Bui, Quan Minh and Do, Dinh-Truong and Le, Nguyen-Khang and Nguyen, Dieu-Hien and Nguyen, Khac-vu-Hiep and Anh, Trang Pham Ngoc},
booktitle = {Proceedings of the Tenth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2023) in association with the 19th International Conference on Artiﬁcial Intelligence and Law},
location = {Braga, Portugal},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {17-26},
url = {},
doi = {},
institution = {}
}

@inproceedings{novaes2023topic-based,
year = {2023},
title = {A Topic-Based Approach for the Legal Case Retrieval Task},
language = {eng},
author = {Novaes, Luisa Pereira and Vianna, Daniela and da Silva, Altigran},
booktitle = {Proceedings of the Tenth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2023) in association with the 19th International Conference on Artiﬁcial Intelligence and Law},
location = {Braga, Portugal},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {27-31},
url = {},
doi = {},
institution = {}
}

@inproceedings{debbarma2023lexical-models,
year = {2023},
title = {{IITDLI}: Legal Case Retrieval Based on Lexical Models},
language = {eng},
author = {Debbarma, Rohan and Prawar, Pratik and Chakraborty, Abhijnan and Bedathur, Srikanta},
booktitle = {Proceedings of the Tenth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2023) in association with the 19th International Conference on Artiﬁcial Intelligence and Law},
location = {Braga, Portugal},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {40-47},
url = {},
doi = {},
institution = {}
}

@techreport{openai2023gpt4,
title={GPT-4 Technical Report}, 
author={OpenAI},
year={2023},
eprint={2303.08774},
archivePrefix={arXiv},
primaryClass={cs.CL},
url = {https://arxiv.org/abs/2303.08774v3},
doi = {10.48550/arXiv.2303.08774},
journal  = {arXiv}
}

@misc{chung2022scaling,
title={Scaling Instruction-Finetuned Language Models}, 
author={Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
year={2022},
eprint={2210.11416},
archivePrefix={arXiv},
primaryClass={cs.LG},
url = {https://arxiv.org/abs/2210.11416v5},
doi = {10.48550/arXiv.2210.11416},
journal  = {arXiv}
}

@inproceedings{bilgin2023amhr,
year = {2023},
title = {{AMHR} Lab 2023 {COLIEE} Competition Approach},
language = {eng},
author = {Bilgin, Onur and Fields, Logan and Laverghetta, Antonio Jr. and Marji, Zaid and Nighojkar, Animesh and Steinle, Stephen and Licato, John},
booktitle = {Proceedings of the Tenth International Competition on Legal Information Extraction/Entailment ({COLIEE} 2023) in association with the 19th International Conference on Artiﬁcial Intelligence and Law},
location = {Braga, Portugal},
editor = {Rabelo, Juliano and Goebel, Randy and Kano, Yoshinobu and Kim, Mi-Young and Satoh, Ken  and Yoshioka, Masaharu},
pages = {77-86},
url = {},
doi = {},
institution = {}
}

@book{hart1961concept,
author = {Hart, H. L. A.},
address = {Oxford},
edition = {Third edition},
language = {eng},
publisher = {Oxford University Press},
series = {Clarendon law series},
title = {The concept of law },
year = {[1961] 2012},
}

@misc{openai2022chatgpt,
author = {OpenAI},
year = {2022},
date = {2022-11-30},
url = {https://openai.com/blog/chatgpt},
howpublished = {Blog post},
title = {Introducing {ChatGPT}}
}

@article{lynch2023chatgpt-creative-threat,
author = {Lynch, Kyle},
institution = {University of Derby},
journal = {University of Derby Magazine},
issue = {17},
year = {2023},
date-accessed = {2023-08-02},
url = {https://www.derby.ac.uk/magazine/issue-17/chat-gpt-threat-creative-industries/},
howpublished = {Blog post},
title = {Is {ChatGPT} a threat to the crative industries?}
}

@article{shiddiq2023chatgpt,
author = {Shidiq, Muhammad},
title = {The use of artificial intelligence-based {ChatGPT} and its challenges for the world of education: from the viewpoint of the development of creative writing skills},
journal = {Proceedings of the International Conference on Education, Society and Humanity},
volume = {1},
number = {1},
year = {2023},
keywords = {},
abstract = {Artificial Intelligence is a system with the same intelligence as humans and is characterized by the ability to learn, adapt, solve problems, make decisions, and understand human language. Artificial Intelligence provides many conveniences in the world of education, such as using several systems such as virtual mentors, voice assistants, innovative content, smart classrooms, automatic assessment, and personalized learning. However, on the other hand, there is the ChatGPT system, an AI-based chatbot with the ability to produce text in various formats—whether formal, informal, or creative writing—that poses challenges in the world of education. The ease of ChatGPT in processing information from text input reduces the originality of work, so it tends to be uncreative. The ability of the Chat-GPT system to understand human language makes it very easy to write creatively, such as writing poems, short stories, novels, or other types of writing whose quality is equivalent to human work. Using the study of creative writing theory, this article aims to discuss the ChatGPT system and its impact on students' lack of creativity in writing skills. This article uses qualitative methods with library research data collection techniques by analyzing scientific journals and other articles relevant to the discussion.},
issn = {2986-5832},
pages = {353-357}
}

@article{oppenheimer2023chatgpt-nothing,
author = {Oppenheimer, Danny},
title = {{ChatGPT} has arrived – and nothing has changed},
journal = {Times Higher Education},
year = {2023},
date = {2023-01-17},
url = {https://www.timeshighereducation.com/campus/chatgpt-has-arrived-and-nothing-has-changed},
date-accessed = {2023-08-02}
}

@article{liu2023gpt-summary,
      title={Summary of {ChatGPT/GPT-4} Research and Perspective Towards the Future of Large Language Models}, 
      author={Yiheng Liu and Tianle Han and Siyuan Ma and Jiayue Zhang and Yuanyuan Yang and Jiaming Tian and Hao He and Antong Li and Mengshen He and Zhengliang Liu and Zihao Wu and Dajiang Zhu and Xiang Li and Ning Qiang and Dingang Shen and Tianming Liu and Bao Ge},
      year={2023},
      eprint={2304.01852},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url = {https://arxiv.org/abs/2304.01852v3},
      doi = {10.48550/arXiv.2304.01852},
journal  = {arXiv}
}

@misc{rattray2023chatgpt-lawyers,
author = {Rattray, Kate},
institution = {Clio},
year = {2022},
date = {2023-07-11},
date-accessed = {2023-08-02},
date = {2022-11-30},
url = {https://www.clio.com/blog/chat-gpt-lawyers/},
howpublished = {Blog post},
title = {Will {ChatGPT} replace lawyers?}
}

@techreport{tri2023chatgpt-law-firms,
title={{ChatGPT} and Generative {AI} within Law Firms Law firms see potential, eye practical use cases and more knowledge  around risks}, 
author={{Thomson Reuters Institute}},
year={2023},
month = {4},
url = {https://www.thomsonreuters.com/en-us/posts/wp-content/uploads/sites/20/2023/04/2023-Chat-GPT-Generative-AI-in-Law-Firms.pdf},
}

@misc{mdr2023gpt-engineer,
author = {{Mischcon de Reya}},
institution = {Mischcon de Reya},
year = {2023},
date = {2023-02-20},
date-accessed = {2023-08-02},
url = {https://www.mishcon.com/news/mishcon-de-reyas-exploration-of-ai-technologies-featured-in-the-media},
howpublished = {Blog post},
title = {Mishcon de Reya's exploration of AI technologies featured in the media}
}

@misc{wakeling2023a&o-harvey,
author = {Wakeling, David},
institution = {Allen & Overy},
year = {2023},
date = {2023-02-15},
date-accessed = {2023-08-02},
url = {https://www.allenovery.com/en-gb/global/news-and-insights/news/ao-announces-exclusive-launch-partnership-with-harvey},
howpublished = {Blog post},
title = {{A&O} announces exclusive launch partnership with Harvey}
}

@misc{us2019small-businesses,
title = {Small Business Reorganization Act of 2019 (US)},
year = {2019},
url = {https://www.congress.gov/bill/116th-congress/house-bill/3311}
}

@article{norton2020small-business,
abstract = {Effective February 19, 2020, Congress enacted new bankruptcy legislation granting debtors the option to elect a new subchapter V of chapter 11 of the bankruptcy code (Subchapter V). This was made possible by the bipartisan legislation known as the Small Business Reorganization Act of 2019 (SBRA).* 1 The SBRA was enacted to provide small business debtors2 the opportunity to reorganize in a cost-effective manner. This Article addresses certain pros and cons of these amendments to the Bankruptcy Code (Code), which will depend upon the eyes of the beholder. [ABSTRACT FROM AUTHOR]},
Author = {Norton III, William L. and Bailey, James B.},
ISSN = {08907862},
Journal = {Emory Bankruptcy Developments Journal},
Keywords = {Small business, Bankruptcy, Corporate reorganizations, Debtor & creditor, Corporate reorganization laws, Legislative amendments},
Number = {2},
Pages = {383-393},
Title = {The pros and cons of the Small Business Reorganization Act of 2019},
Volume = {36},
URL = {https://scholarlycommons.law.emory.edu/ebdj/vol36/iss2/2},
Year = {2020},
}

@misc{italy2022business-crisis,
title = {Code of Business Crisis and Insolvency 2022 (Italy)},
year = {2022},
url = {https://www.normattiva.it/uri-res/N2Ls?urn:nir:stato:decreto.legislativo:2019-01-12;14}
}

@article{vaccari2023msmes-distress,
Author = {Vaccari, Eugenio and Ehmke, David and Burigo, Francesca},
Journal = {Journal of International and Comparative Law},
Number = {},
Pages = {},
Title = {MSMEs in Distress: Regulatory Costs and Efficiency Considerations in the Implementation of Preventive Restructuring Mechanisms: An Anglo-German-Italian Perspective},
Volume = {},
URL = {},
Year = {2023},
note = {accepted for publication}
}

@misc{ireland2020insolvency,
title = {Companies (Rescue Process for Small and Micro Companies) Act 2021 (2020)},
year = {2021},
url = {https://www.irishstatutebook.ie/eli/2021/act/30/section/3/enacted/en/html}
}

@misc{australia2020insolvency-reforms,
title = {Corporations Amendment (Corporate Insolvency Reforms) Act 2020 (Cth) (Act) (Australia)},
year = {2020},
url = {http://classic.austlii.edu.au/au/legis/cth/num_reg/cairr2020202001654694/}
}

@techreport{world-bank2017msme-insolvency,
title={Report on the Treatment of MSME Insolvency}, 
author={{The World Bank}},
year={2017},
url = {https://documents1.worldbank.org/curated/en/973331494264489956/pdf/114823-REVISED-PUBLIC-MSME-Insolvency-report-low-res-final.pdf},
}

@techreport{uncitral2021msme-insolvency,
title={Legislative Recommendations on Insolvency of Micro- and Small Enterprises}, 
author={UNCITRAL},
year= {2021},
url = {https://uncitral.un.org/sites/uncitral.un.org/files/media-documents/uncitral/en/part_5_en.pdf},
}

@techreport{ec2022insolvency,
title = {Proposal for a Directive of the European Parliament and of the Council harmonising certain aspects of insolvency law},
year = {2022},
author = {{European Commission}},
number = {COM/2022/702},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52022PC0702}
}

@techreport{ec2003definition-msme,
title = {Commission Recommendation of 6 May 2003 concerning the definition of micro, small and medium-sized enterprises (Text with EEA relevance) (notified under document number C(2003) 1422},
year = {2003},
author = {{European Commission}},
number = {2003/361/EC},
url = {http://data.europa.eu/eli/reco/2003/361/oj}
}

@book{mokal2018msme,
author = {Mokal, Rizwaan Jameel and Davis, Ronald and Madaus, Stephan and Mazzoni, Alberto and Mevorach, Irit and Romaine, Barbara and Sarra, Janis Pearl and Tirado, Ignacio},
title= {Micro, small, and medium enterprise insolvency: A modular approach},
address = {Oxford},
publisher = {Oxford University Press},
year = {2018},
abstract = {Summary: This volume systematically examines the current process for distressed Micro, Small and Medium Enterprises (MSMEs), and proposes a different, more appropriate, 'modular' approach to the treatment of such entities when faced with insolvency proceedings.},
}

@article{vacacri2022modular,
author = {Vaccari, Eugenio},
journal = {Norton Journal of Bankruptcy Law and Practice},
issue = {31},
number = {5},
language = {eng},
title = {A Modular Approach to Restructuring and Insolvency Law: Executory Contracts and Onerous Property in England and Italy},
year = {2022},
}

@techreport{ns2023insolvency-statistics,
title = {Company Insolvency Statistics: April to June 2023},
author = {{National Statistics}},
year = {2023},
date = {2023-07-28},
url = {https://www.gov.uk/government/statistics/company-insolvency-statistics-april-to-june-2023}
}

@article{walters2020small-business,
author = {Walters, A},
title = {The Small Business Reorganization Act: America's new tool for SME restructuring for the COVID and post-COVID era},
year = {2020},
journal = {The Company Lawyer},
issue = {41},
number = {10},
pages = {324-325},
doi = {},
url = {}
}

@article{hutchinson2021small-companies,
author = {Hutchinson, G B},
title = {The Small Companies Rescue Act – false hope for failing companies?},
year = {2021},
issue = {28},
number = {7},
journal = {Company Law Practice?}
}

@misc{uk2015small-business,
title = {Small Business, Enterprise and Employment Act 2015 (UK)},
year = {2015},
url = {https://www.legislation.gov.uk/ukpga/2015/26/contents/enacted}
}

@misc{uk2015corporate-insolvency,
title = {Corporate Insolvency and Governance Act 2020 (UK)},
year = {2015},
url = {https://www.legislation.gov.uk/ukpga/2020/12/contents/enacted}
}

@article{bittner1990irac,
author = {Bittner, Marie},
issn = {0037-7996},
journal = {Social Studies},
language = {eng},
number = {5},
pages = {227-230},
publisher = {Taylor & Francis},
title = {The IRAC Method of Case Study Analysis: A Legal Model for the Social Studies},
volume = {81},
year = {1990},
}

@book{vaccari2022primer,
author = {Vaccari, Eugenio and Ghio, Emilie},
address = {Cheltenham},
isbn = {9781802204094},
publisher = {Edward Elgar},
title = {English corporate insolvency law: A primer.},
year = {2022},
language = {eng},
}

@article{katz2023gpt-bar-exam,
title={GPT-4 passes the Bar Exam}, 
author={Katz, Daniel Martin and Bommarito, Michael James and Gao, Shang and Arredondo, Pablo},
year={2023},
archivePrefix={SSRN},
primaryClass={cs.CL},
url = {https://ssrn.com/abstract=4389233},
doi = {10.2139/ssrn.4389233},
journal  = {SSRN}
}

@book{vanrossum2009python,
title={Python 3 Reference Manual: (Python Documentation Manual Part 2)},
author={Van Rossum, Guido and Drake, Fred L.},
isbn={9781441412690},
series={Documentation for Python},
year={2009},
publisher={CreateSpace},
address = {Scotts Valley, CA}
}

@misc{microsoft2023azure,
author = {Microsoft},
year = {2023},
url = {https://azure.microsoft.com/en-gb/products/functions},
howpublished = {Computer software},
title = {Azure Functions}
}

@article{xian2016latent,
title={Latent embeddings for zero-shot classification},
author={Xian, Yongqin and Akata, Zeynep and Sharma, Gaurav and Nguyen, Quynh and Hein, Matthias and Schiele, Bernt},
year={2016},
eprint={1603.08895},
archivePrefix={arXiv},
primaryClass={cs.CV},
doi = {10.48550/arXiv.1603.08895},
url = {https://doi.org/10.48550/arXiv.1603.08895}
}

@misc{openai2022ada,
author = {OpenAI},
year = {2022},
date = {2022-12-15},
url = {https://openai.com/blog/new-and-improved-embedding-model},
howpublished = {Blog post},
title = {New and improved embedding model}
}

@inproceedings{reimers2019sentence,
title={Sentence-{BERT}: Sentence embeddings using siamese {BERT}-networks},
author={Reimers, Nils and Gurevych, Iryna},
year = {2019},
language = {eng},
booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing ({EMNLP-IJCNLP})},
location = {Hong Kong, China},
editor = {Inui, Kentaro and Jiang, Jing and Ng, Vincent and Wan, Xiaojun},
publisher = {Association for Computational Linguistics},
pages = {3982–3992},
url = {https://aclanthology.org/D19-1410},
doi = {10.18653/v1/D19-1410},
institution = {}
}

@misc{orban2023mickeybot,
author = {Miklos, Orban},
year = {2023},
date = {2023-03-29},
url = {https://play.google.com/store/apps/details?id=com.omui.lgprompt},
howpublished = {Computer software},
title = {Mickey-bot}
}

@misc{wood2023gpt-law-dataset,
author = {Wood, Thomas},
publisher = {Zenodo},
title = {Evaluation script for insolvency bot},
year = {2023},
url = {https://doi.org/10.5281/zenodo.8292105},
doi = {10.5281/zenodo.8292105},
howpublished = {Dataset}
}

@misc{wood2023insolvency-github,
author = {Wood, Thomas},
publisher = {GitHub},
title = {Evaluate insolvency},
year = {2023},
url = {https://github.com/fastdatascience/evaluate_insolvency},
howpublished = {Code repository}
}
